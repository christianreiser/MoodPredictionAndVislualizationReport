
@article{benjamini_controlling_1995,
	title = {Controlling the {False} {Discovery} {Rate}: {A} {Practical} and {Powerful} {Approach} to {Multiple} {Testing}},
	volume = {57},
	issn = {2517-6161},
	shorttitle = {Controlling the {False} {Discovery} {Rate}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1995.tb02031.x},
	doi = {10.1111/j.2517-6161.1995.tb02031.x},
	abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses — the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
	language = {en},
	number = {1},
	urldate = {2021-11-19},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Benjamini, Yoav and Hochberg, Yosef},
	year = {1995},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1995.tb02031.x},
	keywords = {bonferroni-type procedures, familywise error rate, multiple-comparison procedures, p-values},
	pages = {289--300},
}

@article{vosburg_effects_1998,
	title = {The {Effects} of {Positive} and {Negative} {Mood} on {Divergent}-{Thinking} {Performance}},
	volume = {11},
	issn = {1040-0419},
	url = {https://doi.org/10.1207/s15326934crj1102_6},
	doi = {10.1207/s15326934crj1102_6},
	abstract = {Previous work has shown that positive mood may facilitate creative problem solving. However, studies have also shown positive mood may be detrimental to creative thinking under conditions favoring an optimizing strategy for solution. It is argued herein that the opposite effect is observed under conditions promoting loose processing and satisficing problem-solving strategies. The effects of positive and negative mood on divergent-thinking performance were examined in a quasi-experimental design. The sample comprised 188 arts and psychology students. Mood was measured with an adjective checklist prior to task performance. Real-life divergent-thinking tasks scored for fluency were used as the dependent variables. Results showed natural positive mood to facilitate significantly task performance and negative mood to inhibit it. The re was no effect of arousal. The results suggest that per sons in elevated moods may prefer satisficing strategies, which would lead to a higher number of proposed solutions. Persons in a negative mood may choose optimizing strategies and be more concerned with the quality of their ideas, which is detrimental to performance on this kind of task.},
	number = {2},
	urldate = {2021-11-19},
	journal = {Creativity Research Journal},
	author = {Vosburg, Suzanne K.},
	month = apr,
	year = {1998},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1207/s15326934crj1102\_6},
	pages = {165--172},
}

@article{brand_how_2007,
	title = {How do we learn in a negative mood? {Effects} of a negative mood on transfer and learning},
	volume = {17},
	issn = {0959-4752},
	shorttitle = {How do we learn in a negative mood?},
	url = {https://www.sciencedirect.com/science/article/pii/S0959475206001150},
	doi = {10.1016/j.learninstruc.2006.11.002},
	abstract = {Findings show that both positive and negative mood may hinder or promote information processing. In two experiments, we show that negative mood impairs transfer effects and learning. In the first experiment, N=54 participants drawn from a training course for the Swiss Corps of Fortification Guards first learned to solve the three- and four-disk Tower of Hanoi (ToH) problem to mastery level. After mood induction, they were asked to solve one proximal (five-disk ToH) and two distal transfer tasks (the Missionary and Cannibal Problem and the Katona Card Problem). Participants in a negative mood solved the transfer tasks less efficiently. In the second experiment, this result was replicated with a sample of N=80 participants drawn from a training course for nurses. Additionally, mood affected performance if it was induced before the learning phase; participants in a negative mood needed more repetitions to reach the mastery level and also performed worse in the transfer tasks, although there were no greater mood differences in this problem-solving phase. The implications for the design of learning settings are discussed.},
	language = {en},
	number = {1},
	urldate = {2021-11-19},
	journal = {Learning and Instruction},
	author = {Brand, Serge and Reimer, Torsten and Opwis, Klaus},
	month = feb,
	year = {2007},
	keywords = {Mastery level, Negative mood, Problem solving, Tower of Hanoi, Transfer},
	pages = {1--16},
}

@misc{binz_kevin_intro_2019,
	title = {Intro to {Regularization}},
	url = {https://kevinbinz.com/2019/06/09/regularization/},
	abstract = {Part Of: Machine Learning sequenceFollowup To: Bias vs Variance, Gradient Descent Content Summary: 1100 words, 11 min read In Intro to Gradient Descent, we discussed how loss functions allow optimi…},
	language = {en},
	urldate = {2021-11-18},
	journal = {Fewer Lacunae},
	author = {{Binz, Kevin}},
	month = jun,
	year = {2019},
}

@misc{cushing_barry_e_mitigation_1996,
	title = {Mitigation of recency bias in audit judgment: {The} effect of documentation - {ProQuest}},
	shorttitle = {Mitigation of recency bias in audit judgment},
	url = {https://www.proquest.com/openview/283dcd106582467195de2fee655220f2/1?pq-origsite=gscholar&cbl=31718},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
	language = {en},
	urldate = {2021-11-18},
	author = {Cushing, Barry E},
	year = {1996},
}

@incollection{skowronski_chapter_2014,
	title = {Chapter {Three} - {The} {Fading} {Affect} {Bias}: {Its} {History}, {Its} {Implications}, and {Its} {Future}},
	volume = {49},
	shorttitle = {Chapter {Three} - {The} {Fading} {Affect} {Bias}},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128000526000032},
	abstract = {Recalling a memory often prompts an emotional response. Research examining the fading affect bias (FAB) indicates that the emotional response prompted by positive memories often tends to be stronger than the emotional response prompted by negative memories. This chapter presents an overview of research that has explored the FAB effect. This overview indicates that the FAB reflects two trends: (1) over time, the affect associated with positive memories tends to fade more slowly from event occurrence to event recall than the affect associated with negative memories, and (2) it is more often the case that events that were negative at their occurrence will ultimately come to prompt positive affect-at-recall than it is the case that events that were positive at their occurrence will come to prompt negative affect-at-recall. Research has also revealed that the FAB can be altered by event moderators, situational moderators, and individual-difference moderators. The chapter uses this research review to highlight several needed directions for future research, suggest some theoretical ideas that may underlie the FAB, and discuss some ways in which the FAB might be important to life in a social world.},
	language = {en},
	urldate = {2021-11-18},
	booktitle = {Advances in {Experimental} {Social} {Psychology}},
	publisher = {Academic Press},
	author = {Skowronski, John J. and Walker, W. Richard and Henderson, Dawn X. and Bond, Gary D.},
	editor = {Olson, James M. and Zanna, Mark P.},
	month = jan,
	year = {2014},
	doi = {10.1016/B978-0-12-800052-6.00003-2},
	keywords = {Autobiographical memory, Emotion, Fading affect bias, Memory, Positivity, Self},
	pages = {163--218},
}

@article{samek_explainable_2017,
	title = {Explainable {Artificial} {Intelligence}: {Understanding}, {Visualizing} and {Interpreting} {Deep} {Learning} {Models}},
	shorttitle = {Explainable {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/1708.08296},
	abstract = {With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks.},
	urldate = {2021-11-18},
	journal = {arXiv:1708.08296 [cs, stat]},
	author = {Samek, Wojciech and Wiegand, Thomas and Müller, Klaus-Robert},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.08296},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{loshchilov_decoupled_2019,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	url = {http://arxiv.org/abs/1711.05101},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
	urldate = {2021-11-17},
	journal = {arXiv:1711.05101 [cs, math]},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = jan,
	year = {2019},
	note = {arXiv: 1711.05101},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
}

@article{prechelt_automatic_1998,
	title = {Automatic early stopping using cross validation: quantifying the criteria},
	volume = {11},
	issn = {0893-6080},
	shorttitle = {Automatic early stopping using cross validation},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608098000100},
	doi = {10.1016/S0893-6080(98)00010-0},
	abstract = {Cross validation can be used to detect when overfitting starts during supervised training of a neural network; training is then stopped before convergence to avoid the overfitting (`early stopping'). The exact criterion used for cross validation based early stopping, however, is chosen in an ad-hoc fashion by most researchers or training is stopped interactively. To aid a more well-founded selection of the stopping criterion, 14 different automatic stopping criteria from three classes were evaluated empirically for their efficiency and effectiveness in 12 different classification and approximation tasks using multi-layer perceptrons with RPROP training. The experiments show that, on average, slower stopping criteria allow for small improvements in generalization (in the order of 4\%), but cost about a factor of 4 longer in training time.},
	language = {en},
	number = {4},
	urldate = {2021-11-17},
	journal = {Neural Networks},
	author = {Prechelt, Lutz},
	month = jun,
	year = {1998},
	keywords = {Cross validation, Early stopping, Empirical study, Generalization, Overfitting, Supervised learning},
	pages = {761--767},
}

@article{xu_empirical_2015,
	title = {Empirical {Evaluation} of {Rectified} {Activations} in {Convolutional} {Network}},
	url = {http://arxiv.org/abs/1505.00853},
	abstract = {In this paper we investigate the performance of different types of rectified activation functions in convolutional neural network: standard rectified linear unit (ReLU), leaky rectified linear unit (Leaky ReLU), parametric rectified linear unit (PReLU) and a new randomized leaky rectified linear units (RReLU). We evaluate these activation function on standard image classification task. Our experiments suggest that incorporating a non-zero slope for negative part in rectified activation units could consistently improve the results. Thus our findings are negative on the common belief that sparsity is the key of good performance in ReLU. Moreover, on small scale dataset, using deterministic negative slope or learning it are both prone to overfitting. They are not as effective as using their randomized counterpart. By using RReLU, we achieved 75.68{\textbackslash}\% accuracy on CIFAR-100 test set without multiple test or ensemble.},
	urldate = {2021-11-17},
	journal = {arXiv:1505.00853 [cs, stat]},
	author = {Xu, Bing and Wang, Naiyan and Chen, Tianqi and Li, Mu},
	month = nov,
	year = {2015},
	note = {arXiv: 1505.00853},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{zou_regularization_2005,
	title = {Regularization and variable selection via the elastic net},
	volume = {67},
	issn = {1369-7412, 1467-9868},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2005.00503.x},
	doi = {10.1111/j.1467-9868.2005.00503.x},
	abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping eﬀect, where strongly correlated predictors tend to be in (out) the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p n case. An eﬃcient algorithm called LARS-EN is proposed for computing elastic net regularization paths eﬃciently, much like the LARS algorithm does for the lasso.},
	language = {en},
	number = {2},
	urldate = {2021-11-17},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Zou, Hui and Hastie, Trevor},
	month = apr,
	year = {2005},
	pages = {301--320},
}

@article{durre_robust_2015,
	title = {Robust estimation of (partial) autocorrelation},
	volume = {7},
	issn = {1939-0068},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1351},
	doi = {10.1002/wics.1351},
	abstract = {The autocorrelation function (acf) and the partial autocorrelation function (pacf) are elementary tools of linear time series analysis. The sensitivity of the conventional sample acf and pacf to outliers is well known. We review robust estimators and evaluate their performances in different data situations considering Gaussian scenarios with and without outliers as well as times series with heavy tails in a simulation study. WIREs Comput Stat 2015, 7:205–222. doi: 10.1002/wics.1351 This article is categorized under: Statistical and Graphical Methods of Data Analysis {\textgreater} Robust Methods Data: Types and Structure {\textgreater} Time Series, Stochastic Processes, and Functional Data},
	language = {en},
	number = {3},
	urldate = {2021-11-17},
	journal = {WIREs Computational Statistics},
	author = {Dürre, Alexander and Fried, Roland and Liboschik, Tobias},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1351},
	keywords = {autocovariance, correlogram, outliers, time series},
	pages = {205--222},
}

@misc{noauthor_bipolar_nodate,
	title = {Bipolar disorder - {Symptoms} and causes},
	url = {https://www.mayoclinic.org/diseases-conditions/bipolar-disorder/symptoms-causes/syc-20355955},
	abstract = {Bipolar disorder causes extreme mood swings that include emotional highs (mania or hypomania) and lows (depression).},
	language = {en},
	urldate = {2021-11-16},
	journal = {Mayo Clinic},
}

@book{symposium_neurobiology_1984,
	title = {The {Neurobiology} of {Pain}: {Symposium} of the {Northern} {Neurobiology} {Group}, {Held} at {Leeds} on 18 {April}, 1983},
	isbn = {978-0-7190-1061-3},
	shorttitle = {The {Neurobiology} of {Pain}},
	language = {en},
	publisher = {Manchester University Press},
	author = {Symposium, Northern Neurobiology Group (Great Britain) and Group, Northern Neurobiology},
	year = {1984},
	note = {Google-Books-ID: S7rnAAAAIAAJ},
	keywords = {Medical / General},
}

@article{fedorikhin_positive_2010,
	title = {Positive {Mood} and {Resistance} to {Temptation}: {The} {Interfering} {Influence} of {Elevated} {Arousal}},
	volume = {37},
	issn = {0093-5301},
	shorttitle = {Positive {Mood} and {Resistance} to {Temptation}},
	url = {https://doi.org/10.1086/655665},
	doi = {10.1086/655665},
	abstract = {We investigate the interfering influence of elevated arousal on the impact of positive mood on resistance to temptation. Three studies demonstrate that when a temptation activates long-term health goals, baseline positive mood facilitates resistance to temptation in (1) the choice between two snack items, one of which is more unhealthy, sinful, and hard to resist (M\&amp;Ms) than the other (grapes) and (2) the monitoring of consumption when the sinful option is chosen. However, this influence is attenuated when positive mood is accompanied by elevated arousal. We demonstrate that the cognitive depletion that accompanies elevated arousal interferes with the self-regulatory focus of positive mood, decreasing resistance to temptation.},
	number = {4},
	urldate = {2021-11-16},
	journal = {Journal of Consumer Research},
	author = {Fedorikhin, Alexander and Patrick, Vanessa M.},
	month = dec,
	year = {2010},
	pages = {698--711},
}

@article{xu_l12_2012,
	title = {L1/2 {Regularization}: {A} {Thresholding} {Representation} {Theory} and a {Fast} {Solver}},
	volume = {23},
	issn = {2162-2388},
	shorttitle = {$_{\textrm{1/2}}$ {Regularization}},
	doi = {10.1109/TNNLS.2012.2197412},
	abstract = {The special importance of L1/2 regularization has been recognized in recent studies on sparse modeling (particularly on compressed sensing). The L1/2 regularization, however, leads to a nonconvex, nonsmooth, and non-Lipschitz optimization problem that is difficult to solve fast and efficiently. In this paper, through developing a threshoding representation theory for L1/2 regularization, we propose an iterative half thresholding algorithm for fast solution of L1/2 regularization, corresponding to the well-known iterative soft thresholding algorithm for L1 regularization, and the iterative hard thresholding algorithm for L0 regularization. We prove the existence of the resolvent of gradient of {\textbar}{\textbar}x{\textbar}{\textbar}1/21/2, calculate its analytic expression, and establish an alternative feature theorem on solutions of L1/2 regularization, based on which a thresholding representation of solutions of L1/2 regularization is derived and an optimal regularization parameter setting rule is formulated. The developed theory provides a successful practice of extension of the well- known Moreau's proximity forward-backward splitting theory to the L1/2 regularization case. We verify the convergence of the iterative half thresholding algorithm and provide a series of experiments to assess performance of the algorithm. The experiments show that the half algorithm is effective, efficient, and can be accepted as a fast solver for L1/2 regularization. With the new algorithm, we conduct a phase diagram study to further demonstrate the superiority of L1/2 regularization over L1 regularization.},
	number = {7},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Xu, Zongben and Chang, Xiangyu and Xu, Fengmin and Zhang, Hai},
	month = jul,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {$_{\textrm{q}}$ regularization, Compressive sensing, half, hard, soft, sparsity, thresholding algorithms, thresholding representation theory},
	pages = {1013--1027},
}

@article{hariton_randomised_2018,
	title = {Randomised controlled trials—the gold standard for effectiveness research},
	volume = {125},
	issn = {1470-0328},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6235704/},
	doi = {10.1111/1471-0528.15199},
	number = {13},
	urldate = {2021-11-14},
	journal = {BJOG : an international journal of obstetrics and gynaecology},
	author = {Hariton, Eduardo and Locascio, Joseph J.},
	month = dec,
	year = {2018},
	pmid = {29916205},
	pmcid = {PMC6235704},
	pages = {1716},
}

@article{carlsson_assessment_1983,
	title = {Assessment of chronic pain. {I}. {Aspects} of the reliability and validity of the visual analogue scale:},
	volume = {16},
	issn = {0304-3959},
	shorttitle = {Assessment of chronic pain. {I}. {Aspects} of the reliability and validity of the visual analogue scale},
	url = {http://journals.lww.com/00006396-198305000-00008},
	doi = {10.1016/0304-3959(83)90088-X},
	abstract = {The visual analogue scale (VAS) is a simple and frequently used method for the assessment of variations in intensity of pain. In clinical practice the percentage of pain relief, assessed by VAS, is often considered as a measure of the efficacy of treatment. However, as illustrated in the present study, the validity of VAS estimates performed by patients with chronic pain may be unsatisfactory. Two types of VAS, an absolute and a comparative scale, were compared with respect to factors influencing the reliability and validity of pain estimates. As shown in this study the absolute type of VAS seems to be less sensitive to bias than the comparative one and is therefore preferable for general clinical use. Moreover, the patients appear to differ considerably in their ability to use the VAS reliably. When assessing efficacy of treatment attention should therefore be paid to several complementary indices of pain relief as well as to the individual’s tendency to bias his estimates.},
	language = {en},
	number = {1},
	urldate = {2021-11-14},
	journal = {Pain},
	author = {Carlsson, Anna Maria},
	month = may,
	year = {1983},
	pages = {87--101},
}

@misc{noauthor_pii_nodate,
	title = {{PII}: 0304-3959(83)90088-{X} {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/030439598390088X?token=8EFCEF9E4D772210CB9F4DB19FBBCBBAC0EC681C8C9244DDE8A977D8AD09C8B7111F257A9EA53FD46E19D69C142DC693&originRegion=eu-west-1&originCreation=20211114104038},
	language = {en},
	urldate = {2021-11-14},
	doi = {10.1016/0304-3959(83)90088-X},
	note = {ISSN: 0304-3959},
}

@article{shanmugam_elements_2018,
	title = {Elements of causal inference: foundations and learning algorithms},
	volume = {88},
	issn = {0094-9655, 1563-5163},
	shorttitle = {Elements of causal inference},
	url = {https://www.tandfonline.com/doi/full/10.1080/00949655.2018.1505197},
	doi = {10.1080/00949655.2018.1505197},
	language = {en},
	number = {16},
	urldate = {2021-11-10},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Shanmugam, Ramalingam},
	month = nov,
	year = {2018},
	pages = {3248--3248},
}

@article{reick_estimation_2021,
	title = {Estimation of {Bivariate} {Structural} {Causal} {Models} by {Variational} {Gaussian} {Process} {Regression} {Under} {Likelihoods} {Parametrised} by {Normalising} {Flows}},
	url = {http://arxiv.org/abs/2109.02521},
	abstract = {One major drawback of state-of-the-art artificial intelligence is its lack of explainability. One approach to solve the problem is taking causality into account. Causal mechanisms can be described by structural causal models. In this work, we propose a method for estimating bivariate structural causal models using a combination of normalising flows applied to density estimation and variational Gaussian process regression for post-nonlinear models. It facilitates causal discovery, i.e. distinguishing cause and effect, by either the independence of cause and residual or a likelihood ratio test. Our method which estimates post-nonlinear models can better explain a variety of real-world cause-effect pairs than a simple additive noise model. Though it remains difficult to exploit this benefit regarding all pairs from the T{\textbackslash}"ubingen benchmark database, we demonstrate that combining the additive noise model approach with our method significantly enhances causal discovery.},
	urldate = {2021-11-10},
	journal = {arXiv:2109.02521 [cs, stat]},
	author = {Reick, Nico and Wiewel, Felix and Bartler, Alexander and Yang, Bin},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.02521},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{sontag_lecture_nodate,
	title = {Lecture 14: {Causal} {Inference}, {Part} {I}},
	language = {en},
	author = {Sontag, David and Szolovits, Peter and Guryev, Georgy},
	pages = {12},
}

@article{sontag_lecture_nodate-1,
	title = {Lecture 15: {Causal} {Inference} {Part} {II}},
	language = {en},
	author = {Sontag, David and Szolovits, Peter},
	pages = {8},
}

@book{pearl_causality_2000,
	address = {Cambridge, U.K. ; New York},
	title = {Causality: models, reasoning, and inference},
	isbn = {978-0-521-89560-6 978-0-521-77362-1},
	shorttitle = {Causality},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Pearl, Judea},
	year = {2000},
	keywords = {Causation, Probabilities},
}

@article{shanmugam_elements_2018-1,
	title = {Elements of causal inference: foundations and learning algorithms},
	volume = {88},
	issn = {0094-9655, 1563-5163},
	shorttitle = {Elements of causal inference},
	url = {https://www.tandfonline.com/doi/full/10.1080/00949655.2018.1505197},
	doi = {10.1080/00949655.2018.1505197},
	language = {en},
	number = {16},
	urldate = {2021-11-10},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Shanmugam, Ramalingam},
	month = nov,
	year = {2018},
	pages = {3248--3248},
}

@article{castro_causality_2020,
	title = {Causality matters in medical imaging},
	volume = {11},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-020-17478-w},
	doi = {10.1038/s41467-020-17478-w},
	abstract = {Abstract
            Causal reasoning can shed new light on the major challenges in machine learning for medical imaging: scarcity of high-quality annotated data and mismatch between the development dataset and the target environment. A causal perspective on these issues allows decisions about data collection, annotation, preprocessing, and learning strategies to be made and scrutinized more transparently, while providing a detailed categorisation of potential biases and mitigation techniques. Along with worked clinical examples, we highlight the importance of establishing the causal relationship between images and their annotations, and offer step-by-step recommendations for future studies.},
	language = {en},
	number = {1},
	urldate = {2021-11-10},
	journal = {Nature Communications},
	author = {Castro, Daniel C. and Walker, Ian and Glocker, Ben},
	month = dec,
	year = {2020},
	pages = {3673},
}

@article{castro_joint_nodate,
	title = {Joint {Probabilistic} {Modelling} of {Images} and {Non}-imaging {Covariates}: {A} {Causal} {Perspective}},
	language = {en},
	author = {Castro, Daniel COELHO DE},
	pages = {189},
}

@article{pawlowski_deep_2020,
	title = {Deep {Structural} {Causal} {Models} for {Tractable} {Counterfactual} {Inference}},
	url = {http://arxiv.org/abs/2006.06485},
	abstract = {We formulate a general framework for building structural causal models (SCMs) with deep learning components. The proposed approach employs normalising ﬂows and variational inference to enable tractable inference of exogenous noise variables—a crucial step for counterfactual inference that is missing from existing deep causal learning methods. Our framework is validated on a synthetic dataset built on MNIST as well as on a real-world medical dataset of brain MRI scans. Our experimental results indicate that we can successfully train deep SCMs that are capable of all three levels of Pearl’s ladder of causation: association, intervention, and counterfactuals, giving rise to a powerful new approach for answering causal questions in imaging applications and beyond. The code for all our experiments is available at https://github.com/biomedia-mira/deepscm.},
	language = {en},
	urldate = {2021-11-10},
	journal = {arXiv:2006.06485 [cs, stat]},
	author = {Pawlowski, Nick and Castro, Daniel C. and Glocker, Ben},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.06485},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{pearl_seven_2019,
	title = {The seven tools of causal inference, with reflections on machine learning},
	volume = {62},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3241036},
	doi = {10.1145/3241036},
	abstract = {The kind of causal inference seen in natural human thought can be "algorithmitized" to help produce human-level machine intelligence.},
	language = {en},
	number = {3},
	urldate = {2021-11-10},
	journal = {Communications of the ACM},
	author = {Pearl, Judea},
	month = feb,
	year = {2019},
	pages = {54--60},
}

@article{pearl_causal_nodate,
	title = {Causal {Inference} in {Statistics}},
	language = {en},
	author = {Pearl, Judea},
	pages = {159},
}

@article{kalainathan_structural_2021,
	title = {Structural {Agnostic} {Modeling}: {Adversarial} {Learning} of {Causal} {Graphs}},
	shorttitle = {Structural {Agnostic} {Modeling}},
	url = {http://arxiv.org/abs/1803.04929},
	abstract = {A new causal discovery method, Structural Agnostic Modeling (SAM), is presented in this paper. Leveraging both conditional independencies and distributional asymmetries in the data, SAM aims to ﬁnd the underlying causal structure from observational data. The approach is based on a game between different players estimating each variable distribution conditionally to the others as a neural net, and an adversary aimed at discriminating the overall joint conditional distribution, and that of the original data. A learning criterion combining distribution estimation, sparsity and acyclicity constraints is used to enforce the end-to-end optimization of the graph structure and parameters through stochastic gradient descent. Besides a theoretical analysis of the approach in the large sample limit, SAM is extensively experimentally validated on synthetic and real data.},
	language = {en},
	urldate = {2021-11-10},
	journal = {arXiv:1803.04929 [stat]},
	author = {Kalainathan, Diviyan and Goudet, Olivier and Guyon, Isabelle and Lopez-Paz, David and Sebag, Michèle},
	month = sep,
	year = {2021},
	note = {arXiv: 1803.04929},
	keywords = {Statistics - Machine Learning},
}

@book{escalante_explainable_2018,
	address = {Cham},
	series = {The {Springer} {Series} on {Challenges} in {Machine} {Learning}},
	title = {Explainable and {Interpretable} {Models} in {Computer} {Vision} and {Machine} {Learning}},
	isbn = {978-3-319-98130-7 978-3-319-98131-4},
	url = {http://link.springer.com/10.1007/978-3-319-98131-4},
	language = {en},
	urldate = {2021-11-10},
	publisher = {Springer International Publishing},
	editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Baró, Xavier and Güçlütürk, Yağmur and Güçlü, Umut and van Gerven, Marcel},
	year = {2018},
	doi = {10.1007/978-3-319-98131-4},
}

@article{goudet_learning_2018,
	title = {Learning {Functional} {Causal} {Models} with {Generative} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1709.05321},
	doi = {10.1007/978-3-319-98131-4},
	abstract = {We introduce a new approach to functional causal modeling from observational data, called Causal Generative Neural Networks (CGNN). CGNN leverages the power of neural networks to learn a generative model of the joint distribution of the observed variables, by minimizing the Maximum Mean Discrepancy between generated and observed data. An approximate learning criterion is proposed to scale the computational cost of the approach to linear complexity in the number of observations. The performance of CGNN is studied throughout three experiments. Firstly, CGNN is applied to cause-effect inference, where the task is to identify the best causal hypothesis out of “X → Y ” and “Y → X”. Secondly, CGNN is applied to the problem of identifying v-structures and conditional independences. Thirdly, CGNN is applied to multivariate functional causal modeling: given a skeleton describing the direct dependences in a set of random variables X = [X1, . . . , Xd], CGNN orients the edges in the skeleton to uncover the directed acyclic causal graph describing the causal structure of the random variables. On all three tasks, CGNN is extensively assessed on both artiﬁcial and real-world data, comparing favorably to the state-of-the-art. Finally, CGNN is extended to handle the case of confounders, where latent variables are involved in the overall causal model.},
	language = {en},
	urldate = {2021-11-10},
	journal = {arXiv:1709.05321 [stat]},
	author = {Goudet, Olivier and Kalainathan, Diviyan and Caillou, Philippe and Guyon, Isabelle and Lopez-Paz, David and Sebag, Michèle},
	year = {2018},
	note = {arXiv: 1709.05321},
	keywords = {Statistics - Machine Learning},
}

@article{reick_estimation_nodate,
	title = {Estimation of {Structural} {Causal} {Models} by {Variational} {Gaussian} {Process} {Regression}},
	abstract = {One major drawback of state-of-the-art artiﬁcial intelligence is its lack of explainability. One approach to solve the problem is taking causality into account instead of only correlations. Causal mechanisms can be described by structural causal models. In this work, we propose a method to estimate bivariate structural causal models by combining normalizing ﬂows, which can be applied in density estimation, and variational Gaussian process regression. Though the method proves useful with artiﬁcial datasets, identifying cause and eﬀect on practical data is still an unresolved problem.},
	language = {en},
	author = {Reick, Nico},
	pages = {73},
}

@misc{welltory_welltory_nodate,
	title = {Welltory - guide to a life of health and productivity},
	url = {https://welltory.com/},
	abstract = {Helping millions reach peak health and productivity. A guide that navigates you to the summit of your potential.},
	language = {en-US},
	urldate = {2021-11-08},
	journal = {Welltory},
	author = {Welltory},
}

@misc{elitehrv_best_nodate,
	title = {Best {Heart} {Rate} {Variability} {Monitor} \& {App}},
	url = {https://elitehrv.com/},
	abstract = {Heart Rate Variability (HRV) tracking app for deep insight into your health, stress, recovery and nervous system balance. Elite HRV's heart rate variability insights help you stay in tune with your body and on track toward your goals.},
	language = {en-US},
	urldate = {2021-11-09},
	journal = {Elite HRV},
	author = {EliteHRV},
}

@misc{fitbit_stress_nodate,
	title = {Stress {Management} - {Stress} {Watch} \& {Monitoring} {\textbar} {Fitbit}},
	url = {https://www.fitbit.com/global/us/technology/stress},
	abstract = {Use the Fitbit Sense smartwatch or the Fitbit Charge 5 tracker to understand how your body is handling stress, gain awareness of your emotional well-being and learn strategies to manage your stress better.},
	language = {en},
	urldate = {2021-11-08},
	author = {FitBit},
}

@misc{hellocodeinc_exist_nodate,
	title = {Exist},
	url = {https://exist.io},
	abstract = {By combining data from services you already use, we can help you understand what makes you more happy, productive, and active.},
	urldate = {2021-11-08},
	author = {HelloCodeInc.},
}

@misc{appleinc_ios_nodate,
	title = {{iOS} - {Health}},
	url = {https://www.apple.com/ios/health/},
	abstract = {The Health app on iPhone puts your important health information at your fingertips, including your health records, labs, activity, sleep, and more.},
	language = {en-US},
	urldate = {2021-11-08},
	journal = {Apple},
	author = {AppleInc.},
}

@article{choudhury_predicting_2013,
	title = {Predicting {Depression} via {Social} {Media}},
	abstract = {Major depression constitutes a serious challenge in personal and public health. Tens of millions of people each year suffer from depression and only a fraction receives adequate treatment. We explore the potential to use social media to detect and diagnose major depressive disorder in individuals. We first employ crowdsourcing to compile a set of Twitter users who report being diagnosed with clinical depression, based on a standard psychometric instrument. Through their social media postings over a year preceding the onset of depression, we measure behavioral attributes relating to social engagement, emotion, language and linguistic styles, ego network, and mentions of antidepressant medications. We leverage these behavioral cues, to build a statistical classifier that provides estimates of the risk of depression, before the reported onset. We find that social media contains useful signals for characterizing the onset of depression in individuals, as measured through decrease in social activity, raised negative affect, highly clustered egonetworks, heightened relational and medicinal concerns, and greater expression of religious involvement. We believe our findings and methods may be useful in developing tools for identifying the onset of major depression, for use by healthcare agencies; or on behalf of individuals, enabling those suffering from depression to be more proactive about their mental health.},
	language = {en},
	author = {Choudhury, Munmun De and Gamon, Michael and Counts, Scott and Horvitz, Eric},
	month = jul,
	year = {2013},
	pages = {10},
}

@article{jaques_multi-task_2015,
	title = {Multi-task, {Multi}-{Kernel} {Learning} for {Estimating} {Individual} {Wellbeing}},
	abstract = {We apply a recently proposed technique – Multi-task Multi-Kernel Learning (MTMKL) – to the problem of modeling students’ wellbeing. Because wellbeing is a complex internal state consisting of several related dimensions, Multi-task learning can be used to classify them simultaneously. Multiple Kernel Learning is used to efﬁciently combine data from multiple modalities. MTMKL combines these approaches using an optimization function similar to a support vector machine (SVM). We show that MTMKL successfully classiﬁes ﬁve dimensions of wellbeing, and provides performance beneﬁts above both SVM and MKL.},
	language = {en},
	author = {Jaques, Natasha and Taylor, Sara and Sano, Akane and Picard, Rosalind},
	month = dec,
	year = {2015},
	pages = {7},
}

@article{jaques_multi-task_2016,
	title = {Multi-task {Learning} for {Predicting} {Health}, {Stress}, and {Happiness}},
	abstract = {Multi-task Learning (MTL) is applied to the problem of predicting next-day health, stress, and happiness using data from wearable sensors and smartphone logs. Three formulations of MTL are compared: i) Multi-task Multi-Kernel learning, which feeds information across tasks through kernel weights on feature types, ii) a Hierarchical Bayes model in which tasks share a common Dirichlet prior, and iii) Deep Neural Networks, which share several hidden layers but have ﬁnal layers unique to each task. We show that by using MTL to leverage data from across the population while still customizing a model for each person, we can account for individual differences, and obtain state-of-the-art performance on this dataset.},
	language = {en},
	author = {Jaques, Natasha and Taylor, Sara and Nosakhare, Ehimwenma and Sano, Akane and Picard, Rosalind},
	month = dec,
	year = {2016},
	pages = {5},
}

@inproceedings{jaques_predicting_2015,
	title = {Predicting students' happiness from physiology, phone, mobility, and behavioral data},
	doi = {10.1109/ACII.2015.7344575},
	abstract = {In order to model students' happiness, we apply machine learning methods to data collected from undergrad students monitored over the course of one month each. The data collected include physiological signals, location, smartphone logs, and survey responses to behavioral questions. Each day, participants reported their wellbeing on measures including stress, health, and happiness. Because of the relationship between happiness and depression, modeling happiness may help us to detect individuals who are at risk of depression and guide interventions to help them. We are also interested in how behavioral factors (such as sleep and social activity) affect happiness positively and negatively. A variety of machine learning and feature selection techniques are compared, including Gaussian Mixture Models and ensemble classification. We achieve 70\% classification accuracy of self-reported happiness on held-out test data.},
	booktitle = {2015 {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} ({ACII})},
	author = {Jaques, Natasha and Taylor, Sara and Azaria, Asaph and Ghandeharioun, Asma and Sano, Akane and Picard, Rosalind},
	month = sep,
	year = {2015},
	note = {ISSN: 2156-8111},
	keywords = {Accelerometers, Atmospheric measurements, Energy measurement, Particle measurements, Physiology, Stress, Stress measurement, happiness, machine learning, wellbeing},
	pages = {222--228},
}

@inproceedings{umematsu_forecasting_2020,
	address = {Montreal, QC, Canada},
	title = {Forecasting stress, mood, and health from daytime physiology in office workers and students},
	isbn = {978-1-72811-990-8},
	url = {https://ieeexplore.ieee.org/document/9176706/},
	doi = {10.1109/EMBC44109.2020.9176706},
	abstract = {We examine the problem of forecasting tomorrow morning’s three self-reported levels (on scales from 0 to 100) of stressed-calm, sad-happy, and sick-healthy based on physiological data (skin conductance, skin temperature, and acceleration) from a sensor worn on the wrist from 10am-5pm today. We train automated forecasting regression algorithms using Random Forests and compare their performance over two sets of data: “workers” consisting of 490 days of weekday data from 39 employees at a high-tech company in Japan and “students” consisting of 3,841 days of weekday data from 201 New England USA college students. Mean absolute errors on held-out test data achieved 10.8, 13.5, and 14.4 for the estimated levels of mood, stress, and health respectively of ofﬁce workers, and 17.8, 20.3, and 20.4 for the mood, stress, and health respectively of students. Overall the two groups reported comparable stress and mood scores, while employees reported slightly poorer health, and engaged in signiﬁcantly lower levels of physical activity as measured by accelerometers. We further examine differences in population features and how systems trained on each population performed when tested on the other.},
	language = {en},
	urldate = {2021-11-08},
	booktitle = {2020 42nd {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} \& {Biology} {Society} ({EMBC})},
	publisher = {IEEE},
	author = {Umematsu, Terumi and Sano, Akane and Taylor, Sara and Tsujikawa, Masanori and Picard, Rosalind W.},
	month = jul,
	year = {2020},
	pages = {5953--5957},
}

@article{taylor_personalized_2020,
	title = {Personalized {Multitask} {Learning} for {Predicting} {Tomorrow}'s {Mood}, {Stress}, and {Health}},
	volume = {11},
	issn = {1949-3045},
	doi = {10.1109/TAFFC.2017.2784832},
	abstract = {While accurately predicting mood and wellbeing could have a number of important clinical benefits, traditional machine learning (ML) methods frequently yield low performance in this domain. We posit that this is because a one-size-fits-all machine learning model is inherently ill-suited to predicting outcomes like mood and stress, which vary greatly due to individual differences. Therefore, we employ Multitask Learning (MTL) techniques to train personalized ML models which are customized to the needs of each individual, but still leverage data from across the population. Three formulations of MTL are compared: i) MTL deep neural networks, which share several hidden layers but have final layers unique to each task; ii) Multi-task Multi-Kernel learning, which feeds information across tasks through kernel weights on feature types; and iii) a Hierarchical Bayesian model in which tasks share a common Dirichlet Process prior. We offer the code for this work in open source. These techniques are investigated in the context of predicting future mood, stress, and health using data collected from surveys, wearable sensors, smartphone logs, and the weather. Empirical results demonstrate that using MTL to account for individual differences provides large performance improvements over traditional machine learning methods and provides personalized, actionable insights.},
	number = {2},
	journal = {IEEE Transactions on Affective Computing},
	author = {Taylor, Sara and Jaques, Natasha and Nosakhare, Ehimwenma and Sano, Akane and Picard, Rosalind},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Affective Computing},
	keywords = {Bayes methods, Data models, Meteorology, Mood, Mood prediction, Predictive models, Stress, deep neural networks, hierarchical Bayesian model, multi-kernel SVM, multitask learning},
	pages = {200--213},
}

@misc{noauthor_happimeterorg_nodate,
	title = {Happimeter.org {\textbar} {A} project of the {Center} for {Collective} {Intelligence} at {MIT}},
	url = {https://www.happimeter.org/},
	urldate = {2021-11-08},
}

@misc{noauthor_pattern_nodate,
	title = {Pattern - {Correlate}, {Health} {Diary}, {Mood}-{Tracker} - {Apps} on {Google} {Play}},
	url = {https://play.google.com/store/apps/details?id=com.pattern.health.diary},
	abstract = {Health Diary For Your Wellbeing. Discover What Works For A Healthier You.},
	language = {en},
	urldate = {2021-11-08},
}

@misc{noauthor_mood_nodate,
	title = {Mood {Tracker} {Journal}. {Mental} {Health}, {Depression} - {Apps} on {Google} {Play}},
	url = {https://play.google.com/store/apps/details?id=diary.questions.mood.tracker},
	abstract = {Mood Tracker Journal for mental health \& self care diary. Relieve depression},
	language = {en},
	urldate = {2021-11-08},
}

@misc{noauthor_moodily_nodate,
	title = {Moodily - {Mood} {Tracker}, {Depression} {Support} - {Apps} on {Google} {Play}},
	url = {https://play.google.com/store/apps/details?id=moodily.rohweller},
	abstract = {Track Your Daily Moods},
	language = {en},
	urldate = {2021-11-08},
}

@misc{noauthor_moodprism_nodate,
	title = {{MoodPrism} {Mental} health and wellbeing app},
	url = {https://www.moodprismapp.com},
	abstract = {MoodPrism is a smartphone app that helps you learn more about yourself by transforming daily mood reports into a colourful summary of your emotional health. You will receive feedback on your mental health and wellbeing, and the more you use the app, the more information you will receive.},
	language = {en-AU},
	urldate = {2021-11-08},
	journal = {MoodPrism Mental health and wellbeing app},
}

@misc{noauthor_moodpanda_nodate,
	title = {{MoodPanda} - {Your} supportive mood diary},
	url = {https://www.moodpanda.com/},
	abstract = {Mobile \& web app for mood-tracking. Analyse your mood on graphs and calendars; get support and advice from the MoodPanda community},
	language = {en},
	urldate = {2021-11-08},
	journal = {MoodPanda.com},
}

@misc{noauthor_daylio_nodate,
	title = {Daylio - {Journal}, {Diary} and {Mood} {Tracker}},
	url = {https://daylio.net/},
	abstract = {Self-Care Bullet Journal with Goals Mood Diary \& Happiness Tracker},
	language = {en-US},
	urldate = {2021-11-08},
	journal = {Daylio},
}

@misc{noauthor_mood_nodate-1,
	title = {Mood {Patterns} - {Mood} tracker \& diary with privacy},
	url = {https://www.moodpatterns.info/},
	abstract = {Gain insights into your feelings},
	language = {en-US},
	urldate = {2021-11-08},
}

@misc{noauthor_features_nodate,
	title = {Features},
	url = {https://www.correlate.com/features/},
	abstract = {Correlate give you the power and flexibility of more complex apps in an easy to use app. Browse through the many powerful features.},
	language = {en-US},
	urldate = {2021-11-08},
	journal = {Correlate.com},
}

@inproceedings{kang_identifying_2016,
	title = {Identifying depressive users in {Twitter} using multimodal analysis},
	doi = {10.1109/BIGCOMP.2016.7425918},
	abstract = {Recently, many efforts have been spent on observing individual's psychological states through analyzing users' social activities on SNS. In this paper, we propose a novel method for identifying the users with depressive moods by analyzing their daily tweets for a long period of time. Then, for more accurately understand their tweets, we exploit all media types of tweets, i.e., images and emoticons as well as texts, thus develop a multimodal method for analyzing them. In the proposed method, three single-modal analyses are first performed for extract the hidden users' moods from text, emoticon, and images: a learning based text analysis, a word-based emoticon analysis, and a SVM based image classifier. Thereafter, the extracted moods from the respective analyses are integrated into a mood and again aggregated per a day, which allows for continuous monitoring of user's mood trends. To assess the validity of the proposed method, two types of experiments were performed: 1) the proposed multimodal analysis was tested with a number of tweets, and its performance was compared to SentiStrength; 2) it was applied to classify 45 users' mental states as depressive and non-depressive ones. Then, the results demonstrated that the proposed method outperforms the baseline, and it is effective in finding depressive moods for users.},
	booktitle = {2016 {International} {Conference} on {Big} {Data} and {Smart} {Computing} ({BigComp})},
	author = {Kang, Keumhee and Yoon, Chanhee and Kim, Eun Yi},
	month = jan,
	year = {2016},
	note = {ISSN: 2375-9356},
	keywords = {Correlation, Internet, Media, Mood, Mood prediction, Sentiment analysis, Twitter, Visualization},
	pages = {231--238},
}

@article{liu_multimodal_2020,
	title = {Multimodal {Privacy}-preserving {Mood} {Prediction} from {Mobile} {Data}: {A} {Preliminary} {Study}},
	shorttitle = {Multimodal {Privacy}-preserving {Mood} {Prediction} from {Mobile} {Data}},
	url = {http://arxiv.org/abs/2012.02359},
	abstract = {Mental health conditions remain under-diagnosed even in countries with common access to advanced medical care. The ability to accurately and efficiently predict mood from easily collectible data has several important implications towards the early detection and intervention of mental health disorders. One promising data source to help monitor human behavior is from daily smartphone usage. However, care must be taken to summarize behaviors without identifying the user through personal (e.g., personally identifiable information) or protected attributes (e.g., race, gender). In this paper, we study behavioral markers or daily mood using a recent dataset of mobile behaviors from high-risk adolescent populations. Using computational models, we find that multimodal modeling of both text and app usage features is highly predictive of daily mood over each modality alone. Furthermore, we evaluate approaches that reliably obfuscate user identity while remaining predictive of daily mood. By combining multimodal representations with privacy-preserving learning, we are able to push forward the performance-privacy frontier as compared to unimodal approaches.},
	urldate = {2021-11-04},
	journal = {arXiv:2012.02359 [cs, stat]},
	author = {Liu, Terrance and Liang, Paul Pu and Muszynski, Michal and Ishii, Ryo and Brent, David and Auerbach, Randy and Allen, Nicholas and Morency, Louis-Philippe},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.02359},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Applications},
}

@article{harper_bayesian_2020,
	title = {A {Bayesian} {Deep} {Learning} {Framework} for {End}-{To}-{End} {Prediction} of {Emotion} from {Heartbeat}},
	issn = {1949-3045, 2371-9850},
	url = {http://arxiv.org/abs/1902.03043},
	doi = {10.1109/TAFFC.2020.2981610},
	abstract = {Automatic prediction of emotion promises to revolutionise human-computer interaction. Recent trends involve fusion of multiple data modalities - audio, visual, and physiological - to classify emotional state. However, in practice, collection of physiological data `in the wild' is currently limited to heartbeat time series of the kind generated by affordable wearable heart monitors. Furthermore, real-world applications of emotion prediction often require some measure of uncertainty over model output, in order to inform downstream decision-making. We present here an end-to-end deep learning model for classifying emotional valence from unimodal heartbeat time series. We further propose a Bayesian framework for modelling uncertainty over these valence predictions, and describe a probabilistic procedure for choosing to accept or reject model output according to the intended application. We benchmarked our framework against two established datasets and achieved peak classification accuracy of 90\%. These results lay the foundation for applications of affective computing in real-world domains such as healthcare, where a high premium is placed on non-invasive collection of data, and predictive certainty.},
	urldate = {2021-11-04},
	journal = {IEEE Transactions on Affective Computing},
	author = {Harper, Ross and Southern, Joshua},
	year = {2020},
	note = {arXiv: 1902.03043},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1--1},
}

@inproceedings{jaques_multimodal_2017,
	title = {Multimodal autoencoder: {A} deep learning approach to filling in missing sensor data and enabling better mood prediction},
	shorttitle = {Multimodal autoencoder},
	doi = {10.1109/ACII.2017.8273601},
	abstract = {To accomplish forecasting of mood in real-world situations, affective computing systems need to collect and learn from multimodal data collected over weeks or months of daily use. Such systems are likely to encounter frequent data loss, e.g. when a phone loses location access, or when a sensor is recharging. Lost data can handicap classifiers trained with all modalities present in the data. This paper describes a new technique for handling missing multimodal data using a specialized denoising autoencoder: the Multimodal Autoencoder (MMAE). Empirical results from over 200 participants and 5500 days of data demonstrate that the MMAE is able to predict the feature values from multiple missing modalities more accurately than reconstruction methods such as principal components analysis (PCA). We discuss several practical benefits of the MMAE's encoding and show that it can provide robust mood prediction even when up to three quarters of the data sources are lost.},
	booktitle = {2017 {Seventh} {International} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction} ({ACII})},
	author = {Jaques, Natasha and Taylor, Sara and Sano, Akane and Picard, Rosalind},
	month = oct,
	year = {2017},
	note = {ISSN: 2156-8111},
	keywords = {Data models, Mood, Noise measurement, Noise reduction, Principal component analysis, Stress, Training},
	pages = {202--208},
}

@article{tov_subjective_2013,
	title = {Subjective {Well}-being},
	url = {https://ink.library.smu.edu.sg/soss_research/1395},
	doi = {10.1002/9781118339893.wbeccp518},
	journal = {Encyclopedia of Cross-Cultural Psychology},
	author = {TOV, William and DIENER, Ed},
	month = jan,
	year = {2013},
}
